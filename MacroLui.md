## 前言
### LID的研究动机
加强数据的可访问性  
1. NLP中大部分技术都假设文本语言已知，许多技术假设所有文本都是同一种语言。
2. 在信息存储和获取中，文档通常是被索引到不同语言集合中的。
3. 对文档语言进行识别，并交给适合的翻译者
4. 语料的搜集和语料库的创建

### LID和文本分类的区别
1. 文本分类采用单词频率对文档进行建模，但是单词在LID中并没有一个普适的概念
2. 在文本分类任务中，分类标签通常只适用于特定数据集。但是LID中语言的概念是独立于领域的
3. 在文本分类中，标签集通常是有限和预定义的，而LID的语言集合有可能是开放的，这意味着系统需要识别训练数据中不存在的语言
4. 在LID中，采用同一语言的文本有时会存在不同的拼写和编码。因此，与单纯属于一个类别不同，相同语言的文本可能含有相当不同的表征。需要对这些表征分别进行建模
5. 一些文本分类方法可以处理文档属于多个类别的问题。在LID中，一个文档可能是多语言的。但是文档总能够划分为多个语言的区块，区块可以小到只有一个单词。这一点与文本分类不同。

### 贡献
1. 解决同一语言的不同来源的文本所呈现的差异性，以及这个差异对LID系统健壮性的影响。chapter 3-5
2. 多语言文档的语言识别。chapter 6
3. 社交媒体和用户生成文本的语言识别。研究意义：帮助用户阅读；用户画像。chapter 7

## 综述
### 2.1 LID简史
在计算方法出现之前，LID最早是用于帮助翻译者，快速筛选出特定语言文档，早期方法包括特殊变音符号、特征词表等。LID作为一个计算任务被Gold提出是在1967。  
自动LID的大多数早期工作集中在口语上，或并不区别书面和口头语言。最早的语言识别计算方法大概是House and Neuburg(1977)，其工作集中在口音上。但他们最主要的贡献是表述了基于对语音信息的统计建模进行LID的可行性。  
对功能性LID程序进行描述的最早工作大概是Beesley(1988)。程序的主要功能是将文档进行划分并发送给对应的机器翻译系统。该方法基于Byte N-gram模型对字母和单词的出现频率建模来进行语言识别。其思想借鉴了语言学中的一个基本事实，即每种语言的字母分布是相对一致的。  
被引用最多的早期工作是Cavnar and Trenkle(1994)，其要点是构建每个文档和每种语言的画像，并比对文档和语言的画像，取相似性最高的。van Noord(1994)对其方法进行了实现，得到一个名为TextCat的系统。被广泛使用，该方法可视为LID的一个里程碑，它推广了byte n-gram 方法的使用。至今仍是评估LID的一个基准方法。

### 2.2 LID的现代方法
现代LID系统可分解为四个步骤：  
1. 文本的表征(representation)
2. 基于文档对语言进行分别建模
3. 一个决定文档与语言的相似度的函数
4. 评分模型预测文档的语言

文本表征的选择包括两个方面：文本的分词和标记(tokens)特征  
文本表征有一系列不同描述，包括：  
* 语音类  
* 字母序列  
* 字节N元模型  
* 字符形状  
* 二分图/三分图 频率  
* 三元模型  
* 语法词  
* 马尔可夫过程  
* 变长N元模型  
* 语法类模型  
* 符号特征  
* 压缩模型  

由于LID没有标准化的数据和评估指标，要比较不同文本表征的有效性是很困难的。因为方法的有效性受到一些参数的影响，如语言的数量、训练数据大小、测试文档的长度。而这些表征的基本思想是很相似的。  

#### 2.2.1 分词
单词模型和字符模型  
字符模型比单词模型更准确，但是二者的结合效果更佳，在识别很相近的语言时，单词模型表现更好  
字符模型、字节模型和字母模型的区别  
字符模型的**数据稀疏问题**  

#### 2.2.2 特征选择
从理论上说，文档的表征就是所有可能的字母序列的空间分布。但是在实践中，这样的空间或是指数级一般的巨大(字符N元)，或是无限的(单词)。  
可行的解法是选择序列的一个子集来表示语言和文档的表征。
