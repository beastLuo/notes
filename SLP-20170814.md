### 4.4 N-gram评估：困惑度
**外在评估(extrinsic evaluation)**：端到端评估(end-to-end)，将语言模型嵌入具体应用中，评估应用的性能。  
外在评估是了解某一组件的改进是否能带来整体性能提升的唯一手段。  
但是端到端评估通常很昂贵，需要几小时甚至几天。  
**内在评估(intrinsic evaluation)** 是在独立于任何应用情况下测量模型质量的一种指标。  
**困惑度** 的思想是给定两个概率模型，更好的模型能够更加拟合测试数据，或者说更好地预测测试数据的细节。  
只有使用相同词典的语言模型的困惑度才是可比较的。  
### 4.5 平滑
最大似然估计存在的最主要问题是**数据稀疏**问题，这是因为最大似然估计是基于训练数据的特定内容，而任何训练数据都不可能包含所有英语单词序列。这意味着大量非零概率的序列在统计时被计为零概率。  
采用**smoothing**来解决这个问题
#### 4.5.1 拉普拉斯平滑
所有单词统计次数+1  
**调整计数(adjested count)**：描述平滑对分子的影响  
**折价(discounting)**：调整计数和原始计数的比值，描述平滑前后统计的变化情况  
#### 4.5.2 Good-Turing Discounting
一些折价算法的思想是使用见过一次的东西的计数来估计未见过的东西的计数  
单项(singleton)：只出现一次的单词或N-gram。  
古德-图灵平滑的基本思想是使用单项的数目来对零计数bigram的频率进行重新估计。  
#### 4.5.3 古德-图灵算法的问题
`Nc`有可能是0
### 4.6 插值
### 4.7 回退
### 4.8 实际问题：工具和数据格式
回退N-gram语言模型常用的数据格式：ARPA格式  
构建语言模型的常用工具：SRILM，Cambridge-CMU toolkit
